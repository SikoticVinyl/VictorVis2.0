{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgboost(X_train, X_val, y_train, y_val, initial_model=None):\n",
    "    \"\"\"\n",
    "    Optimize XGBoost model using a systematic approach.\n",
    "    Returns the best model and a dictionary of results.\n",
    "    \"\"\"\n",
    "    # Step 1: Define base model if none provided\n",
    "    if initial_model is None:\n",
    "        initial_model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42,\n",
    "            eval_metric='rmse'  # Add eval metric here\n",
    "        )\n",
    "    \n",
    "    # Step 2: Define parameter grid for initial search\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200],\n",
    "        'min_child_weight': [1, 3],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    # Step 3: Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=initial_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit grid search without early stopping\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 4: Fine-tune around best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    fine_param_grid = {\n",
    "        'max_depth': [best_params['max_depth'] - 1, best_params['max_depth'], best_params['max_depth'] + 1],\n",
    "        'learning_rate': [best_params['learning_rate'] * 0.5, best_params['learning_rate'], best_params['learning_rate'] * 1.5],\n",
    "        'n_estimators': [best_params['n_estimators'] - 50, best_params['n_estimators'], best_params['n_estimators'] + 50],\n",
    "        'reg_alpha': [0, 0.001, 0.01],  # L1 regularization\n",
    "        'reg_lambda': [0, 0.001, 0.01]   # L2 regularization\n",
    "    }\n",
    "    \n",
    "    # Perform fine-tuning grid search\n",
    "    fine_grid_search = GridSearchCV(\n",
    "        estimator=initial_model,\n",
    "        param_grid=fine_param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    fine_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 5: Create final model with best parameters and early stopping\n",
    "    final_params = fine_grid_search.best_params_.copy()\n",
    "    final_model = xgb.XGBRegressor(\n",
    "        **final_params,\n",
    "        eval_metric='rmse',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Fit final model with early stopping\n",
    "    eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "    final_model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=eval_set,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Step 6: Evaluate final model\n",
    "    train_pred = final_model.predict(X_train)\n",
    "    val_pred = final_model.predict(X_val)\n",
    "    \n",
    "    results = {\n",
    "        'best_params': fine_grid_search.best_params_,\n",
    "        'train_mse': mean_squared_error(y_train, train_pred),\n",
    "        'val_mse': mean_squared_error(y_val, val_pred),\n",
    "        'feature_importance': pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': final_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    }\n",
    "    \n",
    "    return final_model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read/Adjust X_train and y_train Data\n",
    "\n",
    "X_train_full = pd.read_csv('/Users/powellshayne/Desktop/githubrepos/VictorVis2.0/Shayne/X_train.csv')\n",
    "X_train_full = X_train_full.set_index('nickname')\n",
    "X_train_full = X_train_full[['series_count', 'game_count', 'kills_per_game', 'deaths_per_game', 'avg_kills', 'avg_deaths']]\n",
    "\n",
    "y_train_full = pd.read_csv('/Users/powellshayne/Desktop/githubrepos/VictorVis2.0/Shayne/y_train.csv')\n",
    "y_train_full = y_train_full.set_index('nickname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, Test, Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spacy/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    }
   ],
   "source": [
    "#Run Optimization Function\n",
    "optimized_model, optimization_results = optimize_xgboost(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.15000000000000002, 'max_depth': 2, 'n_estimators': 250, 'reg_alpha': 0, 'reg_lambda': 0.01}\n",
      "\n",
      "Training MSE: 3.342552570570211e-05\n",
      "Validation MSE: 0.0028784309165266536\n",
      "\n",
      "Top 10 Important Features:\n",
      "           feature  importance\n",
      "3  deaths_per_game    0.524894\n",
      "2   kills_per_game    0.426764\n",
      "4        avg_kills    0.041488\n",
      "5       avg_deaths    0.004760\n",
      "1       game_count    0.001654\n",
      "0     series_count    0.000439\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print(\"Best Parameters:\", optimization_results['best_params'])\n",
    "print(\"\\nTraining MSE:\", optimization_results['train_mse'])\n",
    "print(\"Validation MSE:\", optimization_results['val_mse'])\n",
    "print(\"\\nTop 10 Important Features:\")\n",
    "print(optimization_results['feature_importance'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test MSE: 0.002730083611904867\n"
     ]
    }
   ],
   "source": [
    "#Final Evaluation on test set\n",
    "\n",
    "X_test = pd.read_csv('/Users/powellshayne/Desktop/githubrepos/VictorVis2.0/Shayne/X_test.csv')\n",
    "X_test = X_test.set_index('nickname')\n",
    "X_test = X_test[['series_count', 'game_count', 'kills_per_game', 'deaths_per_game', 'avg_kills', 'avg_deaths']]\n",
    "\n",
    "y_test = pd.read_csv('/Users/powellshayne/Desktop/githubrepos/VictorVis2.0/Shayne/y_test.csv')\n",
    "y_test = y_test.set_index('nickname')\n",
    "\n",
    "test_pred = optimized_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_pred)\n",
    "print('\\nTest MSE:', test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Results\n",
    "\n",
    "Before optimizing the XGBRegressor model, the Mean-Squared-Error was:\n",
    "> ~0.007\n",
    "\n",
    "After optimization, the XGBRegressor model's Mean-Squared-Error is:\n",
    "> ~0.0027"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
