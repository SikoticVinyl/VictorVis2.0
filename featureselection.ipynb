{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression, RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.utils import resample\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loremipsum')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoded_data = ohe.fit_transform(df[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_col_names = ohe.get_feature_names_out(categorical_columns)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=enc_col_names)\n",
    "display(encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = df.select_dtypes(include=['int64', 'float64'])\n",
    "final_data= pd.concat([num_data,  encoded_df], axis = 1)\n",
    "\n",
    "print(\"Shape of final dataset:\", final_data.shape)\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colname is a placeholder\n",
    "X= final_data.drop('colname', axis=1)\n",
    "y= final_data['colname']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, randomm_state=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "print(corr_with_target.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance from Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=60)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "fi_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(fi_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = final_data.copy()\n",
    "\n",
    "X_pca = pca_df.drop('colname', axis=1)\n",
    "y_pca = pca_df['colname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_scaled= scale.fit_transform(X_pca)\n",
    "\n",
    "print(X_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pca  \u001b[38;5;241m=\u001b[39m PCA()\n\u001b[0;32m----> 2\u001b[0m X_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_scaled\u001b[49m)\n\u001b[1;32m      4\u001b[0m cum_var_rat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "pca  = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "cum_var_rat = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1, len(cum_var_rat)+1), cum_var_rat, 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_95 = np.argmax(cum_var_rat >= 0.95) + 1\n",
    "print(n_components_95)\n",
    "\n",
    "pca_95 = PCA(n_components_95)\n",
    "X_pca_95 = pca_95.fit_transform(X_scaled)\n",
    "\n",
    "print(X_pca_95.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = X.columns\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    pca_95.components_.T,\n",
    "    columns = [f'PC{i+1}' for i in range(n_components_95)],\n",
    "    index = feat_names\n",
    ")\n",
    "\n",
    "for  i in range(3):\n",
    "    print(loadings[f'PC{i+1}'].abs().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "scatter = plt.scatter(X_pca_95[:,0], X_pca_95[:,1],  c=y, cmap='viridis')\n",
    "#identifyhere is a placeholder\n",
    "plt.colorbar(scatter, label='identifyhere')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(X_pca_95, columns = [f'PC{i+1}' for  i in range(n_components_95)])\n",
    "pca_df['colname'] = y\n",
    "\n",
    "correlations = pca_df.corr()['colname'].abs().sort_values(ascending=False)\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi_scores = mutual_info_regression(X, y)\n",
    "mi_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "print(mi_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def stability_selection(X, y, n_iterations=100, sample_fraction=0.75, n_estimators=100):\n",
    "    feature_importances = np.zeros(X.shape[1])\n",
    "    for _ in range(n_iterations):\n",
    "        X_sample, y_sample = resample(X, y, n_samples=int(len(X) * sample_fraction))\n",
    "        rf = RandomForestRegressor(n_estimators=n_estimators, random_state=42)\n",
    "        rf.fit(X_sample, y_sample)\n",
    "        feature_importances += rf.feature_importances_\n",
    "    return pd.Series(feature_importances / n_iterations, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "stab_scores = stability_selection(X, y)\n",
    "print(stab_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
