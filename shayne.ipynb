{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries/Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Traditional ML\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    roc_curve, \n",
    "    auc\n",
    ")\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# System utilities\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access collected data/dataframe\n",
    "#loremipsum is a placeholder\n",
    "df = pd.read_csv('loremipsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if the recorded data is numerical or an object\n",
    "#For models, data should all be numerical\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Cleaning up the data, we want to ensure any data that we collected is all numerical.\n",
    "- If there are only 2 inputs in a column use Label Encoding\n",
    "- If there are more than 2 iputs in a column, use OneHotEncoding\n",
    "- - OHE results in a series of more columns with 0 or 1 as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['colname'] = le.fit_transform(df['colname'])\n",
    "\n",
    "# Converts the column to numerical values\n",
    "# Preferably 1 and 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "ohencoded_df = pd.DataFrame(ohe.fit_transform(df[['colname', 'colname']]).toarray())\n",
    "\n",
    "df = pd.concat([df, ohencoded_df], axis = 1)\n",
    "\n",
    "#After Concating data, you can remove the origina column as to not have the data with varying inputs\n",
    "#May need to change column names for the encoded items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Models/Neural Network\n",
    "- Set up 'X' and 'y'\n",
    "- If needed, utilize scaling/encoding\n",
    "- Train, Test, and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colname and df are placeholders for actual  data that will be used \n",
    "X = df.drop(columns = 'colname')\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colname and df are placeholders\n",
    "y = df['colname']\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train, Test, and Split\n",
    "X_train,  X_test, y_train, y_test  = train_test_split(X, y,  random_state = 60)\n",
    "#Display the split data Train\n",
    "display(X_train[:5])\n",
    "display(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Scaler\n",
    "scale = StandardScaler()\n",
    "\n",
    "X_train_scaled = scale.fit_transform(X_train)\n",
    "X_test_scaled = scale.transform(X_test)\n",
    "display(X_train_scaled[:5])\n",
    "display(X_test_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost + Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr  = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators = 100,\n",
    "    max_depth = 6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree = 0.8,\n",
    "    random_state = 60\n",
    ")\n",
    "\n",
    "xgbr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train_pred  = xgbr.predict(X_train_scaled)\n",
    "xgb_test_pred = xgbr.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = np.column_stack((X_train_scaled, xgb_train_pred))\n",
    "X_test_nn = np.column_stack((X_test, xgb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(64, input_dim=X_train_nn.shape[1], activation='relu'))\n",
    "nn_model.add(Dense(32, activation='relu'))\n",
    "nn_model.add(Dense(1))\n",
    "\n",
    "nn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "nn_model.fit(X_train_nn, y_train,epochs=50,batch_size=32, validation_data=(X_test_nn, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = nn_model.predict(X_test_nn)\n",
    "\n",
    "mse_nn = mean_squared_error(y_test,  y_pred_nn)\n",
    "mse_nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
